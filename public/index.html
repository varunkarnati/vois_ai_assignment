<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Gourmet Grove</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background-color: #121212;
      color: #fff;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100vh;
      text-align: center;
    }

    h1 { margin-bottom: 1rem; }

    .orb {
      width: 100px;
      height: 100px;
      border-radius: 50%;
      background-color: grey;
      margin: 1rem auto;
      transition: 0.3s all;
    }

    .orb.listening { background-color: #4a90e2; }
    .orb.speaking { background-color: #50e3c2; }
    .orb.idle { background-color: #6c757d; }

    #status {
      margin: 1rem;
      font-size: 1rem;
    }

    .btn {
      background-color: #4a90e2;
      color: white;
      border: none;
      padding: 0.8rem 2rem;
      font-size: 1rem;
      border-radius: 20px;
      cursor: pointer;
      margin: 0.5rem;
    }

    .btn:hover { background-color: #3a7bc8; }

    .btn.end {
      background-color: #e94f4f;
    }

    .btn.end:hover {
      background-color: #c93d3d;
    }

    #audio { display: none; }

    #transcript-box {
      max-height: 200px;
      overflow-y: auto;
      margin-top: 1rem;
      padding: 1rem;
      border: 1px solid #444;
      border-radius: 10px;
      width: 80%;
      text-align: left;
    }

    .message.user { color: #ffa07a; }
    .message.assistant { color: #b0e0e6; }

    details {
      margin-top: 1rem;
      width: 80%;
      text-align: left;
      background: #1e1e1e;
      padding: 1rem;
      border-radius: 10px;
    }
  </style>
</head>
<body>
  <h1>üéôÔ∏è Gourmet Grove Assistant</h1>
  <div class="orb idle" id="orb"></div>
  <div id="status">Press Start to Begin</div>
  <div>
    <button class="btn" onclick="startConversation()">Start Conversation</button>
    <button class="btn end" onclick="endConversation()">End Conversation</button>
  </div>

  <div id="transcript-box"></div>

  <details>
    <summary>üßæ Order Summary</summary>
    <ul id="order-items"></ul>
    <p id="order-total">Total: $0.00</p>
  </details>

  <audio id="audio" autoplay></audio>

  <script>
    const statusEl = document.getElementById("status");
    const orb = document.getElementById("orb");
    const audioEl = document.getElementById("audio");
    const startButton = document.querySelector("button.btn");
    const endButton = document.querySelector("button.btn.end");
    const transcriptBox = document.getElementById("transcript-box");

    let ws = null;
    let micStream = null;
    let mediaRecorder = null;
    let audioContext = null;
    let source = null;
    let processor = null;
    let silenceStart = null;
    let recordingStartTime = null;
    let pendingEnd = false;

    const rmsThreshold = 0.005;
    const silenceDuration = 1500;
    const maxRecordingTime = 10000;

    function updateStatus(text, state) {
      statusEl.textContent = text;
      orb.className = `orb ${state}`;
    }

    function appendMessage(role, text) {
      const msg = document.createElement("div");
      msg.className = `message ${role}`;
      msg.textContent = `${role === 'user' ? 'You' : 'Assistant'}: ${text}`;
      transcriptBox.appendChild(msg);
      transcriptBox.scrollTop = transcriptBox.scrollHeight;
    }

    function updateOrderSummary(items, total) {
      const itemsEl = document.getElementById("order-items");
      const totalEl = document.getElementById("order-total");

      itemsEl.innerHTML = "";
      if (items && items.length > 0) {
        items.forEach(item => {
          const li = document.createElement("li");
          li.textContent = item;
          itemsEl.appendChild(li);
        });
      } else {
        const li = document.createElement("li");
        li.textContent = "(No items yet)";
        itemsEl.appendChild(li);
      }

      totalEl.textContent = `Total: $${(typeof total === 'number' ? total : 0).toFixed(2)}`;
    }

    async function initializeMic() {
      micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    }

    async function startConversation() {
      startButton.disabled = true;
      updateStatus("üîå Connecting...", "idle");
      await initializeMic();

      const protocol = location.protocol === 'https:' ? 'wss' : 'ws';
      const wsUrl = `${protocol}//${location.host}/ws/converse`;
      ws = new WebSocket(wsUrl);
      ws.binaryType = "arraybuffer";

      ws = new WebSocket(wsUrl);
      ws.binaryType = "arraybuffer";


      ws.onopen = () => {
        updateStatus("üß† Connected", "idle");
      };

      ws.onmessage = async (event) => {
        const data = JSON.parse(event.data);

        if (data.user) appendMessage("user", data.user);
        if (data.transcript) appendMessage("assistant", data.transcript);

        if (data.order && Array.isArray(data.order.items)) {
          updateOrderSummary(data.order.items, data.order.total || 0);
        }

        if (data.audio) {
          playBase64Audio(data.audio);
          updateStatus("üó£Ô∏è Assistant responding...", "speaking");

          audioEl.onended = () => {
            if (pendingEnd) {
              cleanupConversation();
            } else {
              updateStatus("üé§ Listening...", "listening");
              startRecording();
            }
          };
        }
      };

      ws.onerror = (err) => {
        console.error("WebSocket error:", err);
        updateStatus("‚ùå Connection failed", "idle");
      };
    }

    function endConversation() {
      pendingEnd = true;
      updateStatus("üîö Ending after response...", "idle");
    }

    function cleanupConversation() {
      if (ws) {
        ws.close();
        ws = null;
      }
      if (mediaRecorder?.state === "recording") {
        mediaRecorder.stop();
      }
      if (processor) processor.disconnect();
      if (source) source.disconnect();
      if (audioContext) {
        audioContext.close();
        audioContext = null;
      }
      if (micStream) {
        micStream.getTracks().forEach(t => t.stop());
        micStream = null;
      }
      updateStatus("üî¥ Conversation Ended", "idle");
      startButton.disabled = false;
    }

    function playBase64Audio(base64) {
      const binaryString = atob(base64);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      const blob = new Blob([bytes], { type: "audio/wav" });
      const url = URL.createObjectURL(blob);
      audioEl.src = url;
    }

    async function startRecording() {
      stopRecordingCleanup();
      updateStatus("üé§ Listening...", "listening");
      recordingStartTime = Date.now();
      silenceStart = null;

      const chunks = [];

      if (!audioContext || audioContext.state === 'closed') {
        audioContext = new AudioContext();
      }

      source = audioContext.createMediaStreamSource(micStream);
      processor = audioContext.createScriptProcessor(4096, 1, 1);

      processor.onaudioprocess = (e) => {
        if (!mediaRecorder || mediaRecorder.state !== "recording") return;
        const input = e.inputBuffer.getChannelData(0);
        const rms = Math.sqrt(input.reduce((a, b) => a + b * b, 0) / input.length);
        if (rms < rmsThreshold) {
          if (!silenceStart) silenceStart = Date.now();
          else if (Date.now() - silenceStart > silenceDuration) stopRecordingCleanup();
        } else {
          silenceStart = null;
        }
        if (Date.now() - recordingStartTime > maxRecordingTime) stopRecordingCleanup();
      };

      source.connect(processor);
      processor.connect(audioContext.destination);

      const options = { mimeType: 'audio/webm;codecs=opus' };
      if (!MediaRecorder.isTypeSupported(options.mimeType)) options.mimeType = '';

      mediaRecorder = new MediaRecorder(micStream, options);

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) chunks.push(e.data);
      };

      mediaRecorder.onstop = async () => {
        updateStatus("üß† Processing...", "idle");
        const blob = new Blob(chunks, { type: mediaRecorder.mimeType });
        const wavBuffer = await convertBlobToWav(blob);
        if (ws && ws.readyState === WebSocket.OPEN) {
          ws.send(wavBuffer);
        }
      };

      mediaRecorder.start(500);
    }

    function stopRecordingCleanup() {
      if (mediaRecorder?.state === "recording") mediaRecorder.stop();
      processor?.disconnect();
      source?.disconnect();
      processor = null;
      source = null;
      silenceStart = null;
    }

    async function convertBlobToWav(blob) {
      const arrayBuffer = await blob.arrayBuffer();
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
      const sampleRate = audioBuffer.sampleRate;
      const samples = audioBuffer.getChannelData(0);
      const buffer = new ArrayBuffer(44 + samples.length * 2);
      const view = new DataView(buffer);

      function writeString(view, offset, string) {
        for (let i = 0; i < string.length; i++) {
          view.setUint8(offset + i, string.charCodeAt(i));
        }
      }

      writeString(view, 0, 'RIFF');
      view.setUint32(4, 36 + samples.length * 2, true);
      writeString(view, 8, 'WAVE');
      writeString(view, 12, 'fmt ');
      view.setUint32(16, 16, true);
      view.setUint16(20, 1, true);
      view.setUint16(22, 1, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * 2, true);
      view.setUint16(32, 2, true);
      view.setUint16(34, 16, true);
      writeString(view, 36, 'data');
      view.setUint32(40, samples.length * 2, true);

      let offset = 44;
      for (let i = 0; i < samples.length; i++, offset += 2) {
        let s = Math.max(-1, Math.min(1, samples[i]));
        view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
      }

      return buffer;
    }
  </script>
</body>
</html>
